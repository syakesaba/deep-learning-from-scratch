{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 畳み込み層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 畳み込み層: CNN（Convolutional Neural Network）で新たに取り入れられる層の一つ。\n",
    "- 特徴マップ(feature map): 畳み込み層における入出力データのこと\n",
    "- 入力特徴マップ(input feature map): 畳み込み層における入力データのこと\n",
    "- 出力特徴マップ(output feature map): 畳み込み層における出力データのこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.hpc.co.jp/AboutDeepLearning.html\n",
    "![http://www.hpc.co.jp/images/DL_kaisetsu_09.png](http://www.hpc.co.jp/images/DL_kaisetsu_09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全結合層の問題点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまでのニューラルネットワークは隣接する層のすべてのニューロンとニューロンの間で結合がある（fully-connected; 全結合;）状態だった。  \n",
    "我々はこれまでそれぞれの結合部をAffineレイヤ（行列の内積計算）で実装しReLUにて発火させた。これは何の考慮もせずに入力値をそのまま行列に変換してニューラルネットワークを構築したことになる。つまり今回のMNISTの手書き文字の場合、元々あった縦・横などの「データの形状情報」やRGB（ピクセルの色合いの順序情報;R要素・G要素・B要素の区別;）が失われてしまうことになる。  \n",
    "__データをそのまま全結合層の入力（行列）として扱った場合3次元以上の情報は失われてしまう！__  \n",
    "例えば、画像を行列として扱った場合に失われる情報としては以下が考えられる\n",
    "- ピクセルのR,G,B,Aのそれぞれの濃度\n",
    "- 縦・横のピクセル幅\n",
    "- 上下左右で連続したピクセル間の値の推移"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 畳み込み演算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込み演算は画像処理で言う「フィルター演算」にあたる。  \n",
    "http://www.hpc.co.jp/AboutDeepLearning.html  \n",
    "![http://www.hpc.co.jp/images/DL_kaisetsu_10.png](http://www.hpc.co.jp/images/DL_kaisetsu_10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「フィルター」はカーネルとも呼ばれ、入力データに対してあるウインドウサイズの区画で積和演算を行う。全結合のニューラルネットワークでは行列が重みパラメータとなっていたが、CNNの場合はこのフィルターの乗算内容が「重み」に対応する。  \n",
    "積和演算の結果は各ウィンドウの位置ごとに取得され、結果は新たな出力データとなる。  \n",
    "その出力データの行列にスカラをスカラ加算（行列の要素全てに等しく加算）することでバイアスも実現する。  \n",
    "バイアスはスカラなので、1 x 1の行列となる。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パディング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力データの大外にダミーの枠を用意することで、積和演算結果のサイズを調整できる。  \n",
    "畳み込み演算を繰り返すと段々出力サイズが小さくなるので、最終的な出力サイズが1になることを防ぐことができる。  \n",
    "畳み込み演算回数（隠れ層の数）によっては不要の場合がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ストライド"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フィルターの適用する位置の間隔のこと。積和演算が一回終わった時点でウィンドウがスライドする幅。  \n",
    "パディングとは逆に、ストライドは大きくすると積和演算結果の出力サイズは小さくなる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
