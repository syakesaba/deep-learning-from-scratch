{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習に関するテクニック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[最適化（optimization）](http://www.orsj.or.jp/archive2/or60-4/or60_4_191.pdf)はニューラルネットワークの課題。損失関数（loss function）の値を小さくするようにパラメータを調整することは難しい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "微分の傾きを収束させることを目指す方法。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バッチ勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチ処理により、全てのデータ／テストを一括で順番に計算し勾配を求める。確実だが、リソースの問題がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 確率的勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全てのデータを一括で処理せず、データをある確率分布に基づいて無作為全抽出し勾配を求める。\n",
    "優良なデータを先に処理することが出来る可能性がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ミニバッチ勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全てのデータを一括で処理せず、データをある確率分布に基づいて無作為標本抽出し勾配を求める。\n",
    "サンプリングレート（バッチサイズ）とサンプリング分布（基本的にランダムサンプリングとなる）により\n",
    "優良な標本データを先に処理し目的関数に近づける事ができる。\n",
    "現在の機械学習においては基本的にこの手法が推奨される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 勾配更新アルゴリズムによる収束までの違い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "http://ruder.io/optimizing-gradient-descent/  \n",
    "https://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://sebastianruder.com/content/images/2016/01/saddle_point_evaluation_optimizers.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 様々な勾配降下法の最適化アルゴリズム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SGD(Stochastic Gradient Descent, 確率的勾配降下法)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W \\leftarrow W - \\eta \\frac{\\partial L}{\\partial W}$  \n",
    "$0 \\lt \\eta \\lt 1$  \n",
    "$W::Weight\\ \\ \\eta::Learning\\ Rate\\ \\ L::Loss\\ Function\\ \\ \\partial::Partial\\ Differentiation$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "単純な勾配降下法全てのベース(Vanilla)となる。全集合（学習データ集合、テストデータ集合）の中の一部(batch_size分)の集合をepoch回だけ__無作為サンプリング（サンプリング分布に注意）__し、勾配降下法の計算に反映する手法。大規模なデータを処理する際、少ない計算量で実装可能であり、非常にシンプルなのでMLアルゴリズムのデバッグが容易。__目的関数と一致しない集合で学習してしまうと急激に勾配が上下し目的関数もそれにつられて大きく変動する可能性がある__。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"確率的勾配降下法（Stochastic Gradient Descent）\"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Momentam (Momentam SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$v \\leftarrow \\alpha v - \\eta \\frac{\\partial L}{\\partial W}$  \n",
    "$W \\leftarrow W + v $  \n",
    "$0 \\lt \\alpha \\lt 1$  \n",
    "$v::velocity\\ \\ \\alpha::Air\\ Resistance\\ (aka. Friction)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "SGDにおいて勾配更新の際に勾配を直接計算に反映するのではなく「直前の勾配の加速度」変数を掛け算し続けることでSGDの勾配更新を滑らかにする方法。複雑な関数でなければSGDよりも早く収束する可能性がある。勾配と正方向の加速度が「勢い」であり、逆方向の加速度が物理学でいう「摩擦」や「空気抵抗」に近い。__加速度に定数$\\alpha$を毎回掛け算しているのは、静止摩擦を付加し収束を期待する為である。__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    \"\"\"慣性SGD (Momentam SGD)\"\"\"\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():                                \n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key] \n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAG (Nesterov's Accelerated Gradient) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentamでは加速度を計算する際に勾配計算前の値を使用していたが、NAGでは勾配計算後の値を使用することで、勾配の変化に関してMomentamよりも一歩先で気づくことが出来るようになる。それ以外は特に変わらない。同盟で複数のアルゴリズムが存在する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h \\leftarrow h + \\frac{\\partial L}{\\partial W} \\odot \\frac{\\partial L}{\\partial W}$  \n",
    "$W \\leftarrow W - \\eta \\frac{1}{\\sqrt{h}} \\frac{\\partial L}{\\partial W}$  \n",
    "$h::Rate\\ of\\ Learning\\ Rate\\ \\ \\odot::Hadamard\\ Product (アダマール積::行列の要素ごとの単純乗算。内積でない。)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "勾配更新の際に「学習率」自体を勾配で自乗したもので割る。これにより学習率そのものの指数関数的な減衰をもたらす。最初の勾配が大きいものが強く学習され、収束に従って緩やかに学習されるようになるので最初に大きく学習を進めることが出来る。最初に学習したデータが良好なデータであればあるほど効果的に働くが学習が進むに連れて学習率が0に近づく為、__オンライン学習（継続的学習）の場合は新鮮なデータを受け入れるのが難しくなる欠点がある__。アダマール積を使用しているのは、各種パラメータ（行・列）毎のデータ変動を一個ずつ対応して反映できるようにするためである。※$h$は最初は非常に小さな数値に設定し、ゼロ除算を回避すること。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"AdaGrad (Adaptive subgradient methods for online learning and stochastic optimization)\"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "        for key in params.keys():\n",
    "            self.h[key] += grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n",
    "            #1e-7はゼロ除算を防ぐため"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$h \\leftarrow \\alpha h + (1-\\alpha)\\frac{\\partial L}{\\partial W} \\odot \\frac{\\partial L}{\\partial W}$  \n",
    "$W \\leftarrow W - \\eta \\frac{1}{\\sqrt{h}} \\frac{\\partial L}{\\partial W}$  \n",
    "$0 \\le \\alpha \\le 1$  \n",
    "$\\alpha::Rate\\ of\\ exponential\\ moving\\ average;EMA;指数移動平均の割合定数。$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adagradにおいて学習が進むにつれて新鮮なデータを受入し難くなる欠点を克服するため、__一つ前の学習率に定数$\\alpha$を掛けて減衰させ、受け入れる新鮮なデータの学習率の影響を強める__手法。hに関して指数移動平均を適用したものである。過去のデータの影響力の加重が指数関数的に減衰するので、$\\alpha$の数値が低すぎた場合は過去のデータの影響力が直ちに低下してしまい、新鮮すぎる結果が発生し、数値が高すぎた場合は腐った結果が発生するリスクがある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSprop:\n",
    "    \"\"\"RMSprop\"\"\"\n",
    "    def __init__(self, lr=0.01, decay_rate = 0.99):\n",
    "        self.lr = lr\n",
    "        self.decay_rate = decay_rate\n",
    "        self.h = None\n",
    "    def update(self, params, grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "        for key in params.keys():\n",
    "            self.h[key] *= self.decay_rate\n",
    "            self.h[key] += (1 - self.decay_rate) * grads[key] * grads[key]\n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaDelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdagradとRMSpropをあわせたもの。学習率が存在せず移動平均がそのまま学習率に反映される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaGrad、RMSprop、AdaDeltaを合わせスケールを追加したもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    \"\"\"Adam (Adaptive moment estimation)\"\"\"\n",
    "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None        \n",
    "    def update(self, params, grads):\n",
    "        if self.m is None:\n",
    "            self.m, self.v = {}, {}\n",
    "            for key, val in params.items():\n",
    "                self.m[key] = np.zeros_like(val)\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        self.iter += 1\n",
    "        lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         \n",
    "        for key in params.keys():\n",
    "            #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]\n",
    "            #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)\n",
    "            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])\n",
    "            self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])\n",
    "            \n",
    "            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)\n",
    "            \n",
    "            #unbias_m += (1 - self.beta1) * (grads[key] - self.m[key]) # correct bias\n",
    "            #unbisa_b += (1 - self.beta2) * (grads[key]*grads[key] - self.v[key]) # correct bias\n",
    "            #params[key] += self.lr * unbias_m / (np.sqrt(unbisa_b) + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
