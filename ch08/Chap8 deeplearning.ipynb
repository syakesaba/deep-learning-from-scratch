{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# ディープラーニング"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## ディープな手書き数字認識"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "- 3x3の小さなフィルターによる畳込み層\n- 活性化関数はReLU\n- 全結合層の後にDropoutレイヤを使用\n- Adamによる最適化\n- 重みの初期値として「Heの初期値」を使用"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# coding: utf-8\nimport sys, os\nsys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\nimport pickle\nimport numpy as np\nfrom collections import OrderedDict\nfrom common.layers import *\n\n\nclass DeepConvNet:\n    \"\"\"認識率99%以上の高精度なConvNet\n\n    ネットワーク構成は下記の通り\n        conv - relu - conv- relu - pool -\n        conv - relu - conv- relu - pool -\n        conv - relu - conv- relu - pool -\n        affine - relu - dropout - affine - dropout - softmax\n    \"\"\"\n    def __init__(self, input_dim=(1, 28, 28),\n                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n                 hidden_size=50, output_size=10):\n        # 重みの初期化===========\n        # 各層のニューロンひとつあたりが、前層のニューロンといくつのつながりがあるか（TODO:自動で計算する）\n        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n        wight_init_scales = np.sqrt(2.0 / pre_node_nums)  # ReLUを使う場合に推奨される初期値\n        \n        self.params = {}\n        pre_channel_num = input_dim[0]\n        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n            self.params['W' + str(idx+1)] = wight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n            pre_channel_num = conv_param['filter_num']\n        self.params['W7'] = wight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n        self.params['b7'] = np.zeros(hidden_size)\n        self.params['W8'] = wight_init_scales[7] * np.random.randn(hidden_size, output_size)\n        self.params['b8'] = np.zeros(output_size)\n\n        # レイヤの生成===========\n        self.layers = []\n        self.layers.append(Convolution(self.params['W1'], self.params['b1'], \n                           conv_param_1['stride'], conv_param_1['pad']))\n        self.layers.append(Relu())\n        self.layers.append(Convolution(self.params['W2'], self.params['b2'], \n                           conv_param_2['stride'], conv_param_2['pad']))\n        self.layers.append(Relu())\n        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n        self.layers.append(Convolution(self.params['W3'], self.params['b3'], \n                           conv_param_3['stride'], conv_param_3['pad']))\n        self.layers.append(Relu())\n        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n                           conv_param_4['stride'], conv_param_4['pad']))\n        self.layers.append(Relu())\n        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n                           conv_param_5['stride'], conv_param_5['pad']))\n        self.layers.append(Relu())\n        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n                           conv_param_6['stride'], conv_param_6['pad']))\n        self.layers.append(Relu())\n        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n        self.layers.append(Relu())\n        self.layers.append(Dropout(0.5))\n        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n        self.layers.append(Dropout(0.5))\n        \n        self.last_layer = SoftmaxWithLoss()\n\n    def predict(self, x, train_flg=False):\n        for layer in self.layers:\n            if isinstance(layer, Dropout):\n                x = layer.forward(x, train_flg)\n            else:\n                x = layer.forward(x)\n        return x\n\n    def loss(self, x, t):\n        y = self.predict(x, train_flg=True)\n        return self.last_layer.forward(y, t)\n\n    def accuracy(self, x, t, batch_size=100):\n        if t.ndim != 1 : t = np.argmax(t, axis=1)\n\n        acc = 0.0\n\n        for i in range(int(x.shape[0] / batch_size)):\n            tx = x[i*batch_size:(i+1)*batch_size]\n            tt = t[i*batch_size:(i+1)*batch_size]\n            y = self.predict(tx, train_flg=False)\n            y = np.argmax(y, axis=1)\n            acc += np.sum(y == tt)\n\n        return acc / x.shape[0]\n\n    def gradient(self, x, t):\n        # forward\n        self.loss(x, t)\n\n        # backward\n        dout = 1\n        dout = self.last_layer.backward(dout)\n\n        tmp_layers = self.layers.copy()\n        tmp_layers.reverse()\n        for layer in tmp_layers:\n            dout = layer.backward(dout)\n\n        # 設定\n        grads = {}\n        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n            grads['b' + str(i+1)] = self.layers[layer_idx].db\n\n        return grads\n\n    def save_params(self, file_name=\"params.pkl\"):\n        params = {}\n        for key, val in self.params.items():\n            params[key] = val\n        with open(file_name, 'wb') as f:\n            pickle.dump(params, f)\n\n    def load_params(self, file_name=\"params.pkl\"):\n        with open(file_name, 'rb') as f:\n            params = pickle.load(f)\n        for key, val in params.items():\n            self.params[key] = val\n\n        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n            self.layers[layer_idx].b = self.params['b' + str(i+1)]",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from graphviz import Digraph\ndot = Digraph(comment=\"上記ディープラーニングのグラフ\")\ndot.attr(rankdir=\"LR\")\n#dot.attr(splines=\"\") #line or curved or ortho or polyline;\ndot.attr(fixedsize=\"true\")\ndot.attr(label=\"上記ディープラーニングのグラフ\")\nwith dot.subgraph(name=\"main\") as main:\n    main.node(\"L1\",\"Conv\")\n    main.node(\"L2\",\"ReLU\")\n    main.node(\"L3\",\"Conv\")\n    main.node(\"L4\",\"ReLU\")\n    main.node(\"L5\",\"Pool\")\n    main.node(\"L6\",\"Conv\")\n    main.node(\"L7\",\"RelU\")\n    main.node(\"L8\",\"Conv\")\n    main.node(\"L9\",\"ReLU\")\n    main.node(\"L10\",\"Pool\")\n    main.node(\"L11\",\"Conv\")\n    main.node(\"L12\",\"RelU\")\n    main.node(\"L13\",\"Conv\")\n    main.node(\"L14\",\"ReLU\")\n    main.node(\"L15\",\"Pool\")\n    main.node(\"L16\",\"Affine\")\n    main.node(\"L17\",\"RelU\")\n    main.node(\"L18\",\"Dropout\")\n    main.node(\"L19\",\"Affine\")\n    main.node(\"L20\",\"Dropout\")\n    main.node(\"L21\",\"Softmax\")\n    main.edge(\"L1\", \"L2\",label=\"\")\n    main.edge(\"L2\", \"L3\",label=\"\")\n    main.edge(\"L3\", \"L4\",label=\"\")\n    main.edge(\"L4\", \"L5\",label=\"\")\n    main.edge(\"L5\", \"L6\",label=\"\")\n    main.edge(\"L6\", \"L7\",label=\"\")\n    main.edge(\"L7\", \"L8\",label=\"\")\n    main.edge(\"L8\", \"L9\",label=\"\")\n    main.edge(\"L9\", \"L10\",label=\"\")\n    main.edge(\"L10\", \"L11\",label=\"\")\n    main.edge(\"L11\", \"L12\",label=\"\")\n    main.edge(\"L12\", \"L13\",label=\"\")\n    main.edge(\"L13\", \"L14\",label=\"\")\n    main.edge(\"L14\", \"L15\",label=\"\")\n    main.edge(\"L15\", \"L16\",label=\"\")\n    main.edge(\"L16\", \"L17\",label=\"\")\n    main.edge(\"L17\", \"L18\",label=\"\")\n    main.edge(\"L18\", \"L19\",label=\"\")\n    main.edge(\"L19\", \"L20\",label=\"\")\n    main.edge(\"L20\", \"L21\",label=\"\")\n    #print(dot)\ndot",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "<graphviz.dot.Digraph at 0x7ff9d4c63f60>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"2062pt\" height=\"67pt\"\n viewBox=\"0.00 0.00 2062.50 67.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 63)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-63 2058.5,-63 2058.5,4 -4,4\"/>\n<text text-anchor=\"middle\" x=\"1027.25\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\">上記ディープラーニングのグラフ</text>\n<!-- L1 -->\n<g id=\"node1\" class=\"node\"><title>L1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"29.8973\" cy=\"-41\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"29.8973\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv</text>\n</g>\n<!-- L2 -->\n<g id=\"node2\" class=\"node\"><title>L2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"128.292\" cy=\"-41\" rx=\"32.4942\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"128.292\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">ReLU</text>\n</g>\n<!-- L1&#45;&gt;L2 -->\n<g id=\"edge1\" class=\"edge\"><title>L1&#45;&gt;L2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.8189,-41C67.9501,-41 76.9578,-41 85.673,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"85.6995,-44.5001 95.6995,-41 85.6994,-37.5001 85.6995,-44.5001\"/>\n</g>\n<!-- L3 -->\n<g id=\"node3\" class=\"node\"><title>L3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"226.686\" cy=\"-41\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"226.686\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv</text>\n</g>\n<!-- L2&#45;&gt;L3 -->\n<g id=\"edge2\" class=\"edge\"><title>L2&#45;&gt;L3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M160.855,-41C169.052,-41 177.982,-41 186.519,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"186.663,-44.5001 196.663,-41 186.663,-37.5001 186.663,-44.5001\"/>\n</g>\n<!-- L4 -->\n<g id=\"node4\" class=\"node\"><title>L4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"325.081\" cy=\"-41\" rx=\"32.4942\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"325.081\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">ReLU</text>\n</g>\n<!-- L3&#45;&gt;L4 -->\n<g id=\"edge3\" class=\"edge\"><title>L3&#45;&gt;L4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M256.608,-41C264.739,-41 273.747,-41 282.462,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"282.488,-44.5001 292.488,-41 282.488,-37.5001 282.488,-44.5001\"/>\n</g>\n<!-- L5 -->\n<g id=\"node5\" class=\"node\"><title>L5</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"420.578\" cy=\"-41\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"420.578\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Pool</text>\n</g>\n<!-- L4&#45;&gt;L5 -->\n<g id=\"edge4\" class=\"edge\"><title>L4&#45;&gt;L5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M357.735,-41C366.021,-41 375.015,-41 383.512,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"383.549,-44.5001 393.549,-41 383.549,-37.5001 383.549,-44.5001\"/>\n</g>\n<!-- L6 -->\n<g id=\"node6\" class=\"node\"><title>L6</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"513.475\" cy=\"-41\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"513.475\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv</text>\n</g>\n<!-- L5&#45;&gt;L6 -->\n<g id=\"edge5\" class=\"edge\"><title>L5&#45;&gt;L6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M447.869,-41C455.772,-41 464.62,-41 473.173,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"473.375,-44.5001 483.375,-41 473.375,-37.5001 473.375,-44.5001\"/>\n</g>\n<!-- L7 -->\n<g id=\"node7\" class=\"node\"><title>L7</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"608.62\" cy=\"-41\" rx=\"29.4969\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"608.62\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">RelU</text>\n</g>\n<!-- L6&#45;&gt;L7 -->\n<g id=\"edge6\" class=\"edge\"><title>L6&#45;&gt;L7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M543.436,-41C551.561,-41 560.525,-41 569.111,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"569.316,-44.5001 579.316,-41 569.316,-37.5001 569.316,-44.5001\"/>\n</g>\n<!-- L8 -->\n<g id=\"node8\" class=\"node\"><title>L8</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"703.765\" cy=\"-41\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"703.765\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv</text>\n</g>\n<!-- L7&#45;&gt;L8 -->\n<g id=\"edge7\" class=\"edge\"><title>L7&#45;&gt;L8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M638.073,-41C646.136,-41 655.058,-41 663.635,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"663.844,-44.5001 673.844,-41 663.843,-37.5001 663.844,-44.5001\"/>\n</g>\n<!-- L9 -->\n<g id=\"node9\" class=\"node\"><title>L9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"802.159\" cy=\"-41\" rx=\"32.4942\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"802.159\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">ReLU</text>\n</g>\n<!-- L8&#45;&gt;L9 -->\n<g id=\"edge8\" class=\"edge\"><title>L8&#45;&gt;L9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M733.686,-41C741.817,-41 750.825,-41 759.54,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"759.567,-44.5001 769.567,-41 759.567,-37.5001 759.567,-44.5001\"/>\n</g>\n<!-- L10 -->\n<g id=\"node10\" class=\"node\"><title>L10</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"897.656\" cy=\"-41\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"897.656\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Pool</text>\n</g>\n<!-- L9&#45;&gt;L10 -->\n<g id=\"edge9\" class=\"edge\"><title>L9&#45;&gt;L10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M834.813,-41C843.099,-41 852.094,-41 860.591,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"860.628,-44.5001 870.628,-41 860.628,-37.5001 860.628,-44.5001\"/>\n</g>\n<!-- L11 -->\n<g id=\"node11\" class=\"node\"><title>L11</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"990.554\" cy=\"-41\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"990.554\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv</text>\n</g>\n<!-- L10&#45;&gt;L11 -->\n<g id=\"edge10\" class=\"edge\"><title>L10&#45;&gt;L11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M924.948,-41C932.85,-41 941.699,-41 950.251,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"950.453,-44.5001 960.453,-41 950.453,-37.5001 950.453,-44.5001\"/>\n</g>\n<!-- L12 -->\n<g id=\"node12\" class=\"node\"><title>L12</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1085.7\" cy=\"-41\" rx=\"29.4969\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1085.7\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">RelU</text>\n</g>\n<!-- L11&#45;&gt;L12 -->\n<g id=\"edge11\" class=\"edge\"><title>L11&#45;&gt;L12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1020.51,-41C1028.64,-41 1037.6,-41 1046.19,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1046.39,-44.5001 1056.39,-41 1046.39,-37.5001 1046.39,-44.5001\"/>\n</g>\n<!-- L13 -->\n<g id=\"node13\" class=\"node\"><title>L13</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1180.84\" cy=\"-41\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1180.84\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv</text>\n</g>\n<!-- L12&#45;&gt;L13 -->\n<g id=\"edge12\" class=\"edge\"><title>L12&#45;&gt;L13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1115.15,-41C1123.21,-41 1132.14,-41 1140.71,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1140.92,-44.5001 1150.92,-41 1140.92,-37.5001 1140.92,-44.5001\"/>\n</g>\n<!-- L14 -->\n<g id=\"node14\" class=\"node\"><title>L14</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1279.24\" cy=\"-41\" rx=\"32.4942\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1279.24\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">ReLU</text>\n</g>\n<!-- L13&#45;&gt;L14 -->\n<g id=\"edge13\" class=\"edge\"><title>L13&#45;&gt;L14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1210.76,-41C1218.9,-41 1227.9,-41 1236.62,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1236.65,-44.5001 1246.65,-41 1236.65,-37.5001 1236.65,-44.5001\"/>\n</g>\n<!-- L15 -->\n<g id=\"node15\" class=\"node\"><title>L15</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1374.73\" cy=\"-41\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1374.73\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Pool</text>\n</g>\n<!-- L14&#45;&gt;L15 -->\n<g id=\"edge14\" class=\"edge\"><title>L14&#45;&gt;L15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1311.89,-41C1320.18,-41 1329.17,-41 1337.67,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1337.71,-44.5001 1347.71,-41 1337.71,-37.5001 1337.71,-44.5001\"/>\n</g>\n<!-- L16 -->\n<g id=\"node16\" class=\"node\"><title>L16</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1471.53\" cy=\"-41\" rx=\"33.5952\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1471.53\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Affine</text>\n</g>\n<!-- L15&#45;&gt;L16 -->\n<g id=\"edge15\" class=\"edge\"><title>L15&#45;&gt;L16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1401.89,-41C1409.85,-41 1418.81,-41 1427.57,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1427.69,-44.5001 1437.69,-41 1427.69,-37.5001 1427.69,-44.5001\"/>\n</g>\n<!-- L17 -->\n<g id=\"node17\" class=\"node\"><title>L17</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1570.58\" cy=\"-41\" rx=\"29.4969\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1570.58\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">RelU</text>\n</g>\n<!-- L16&#45;&gt;L17 -->\n<g id=\"edge16\" class=\"edge\"><title>L16&#45;&gt;L17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1505.39,-41C1513.67,-41 1522.64,-41 1531.18,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1531.29,-44.5001 1541.29,-41 1531.29,-37.5001 1531.29,-44.5001\"/>\n</g>\n<!-- L18 -->\n<g id=\"node18\" class=\"node\"><title>L18</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1676.12\" cy=\"-41\" rx=\"40.0939\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1676.12\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n</g>\n<!-- L17&#45;&gt;L18 -->\n<g id=\"edge17\" class=\"edge\"><title>L17&#45;&gt;L18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1599.87,-41C1607.79,-41 1616.64,-41 1625.41,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1625.61,-44.5001 1635.61,-41 1625.61,-37.5001 1625.61,-44.5001\"/>\n</g>\n<!-- L19 -->\n<g id=\"node19\" class=\"node\"><title>L19</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1786.21\" cy=\"-41\" rx=\"33.5952\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1786.21\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Affine</text>\n</g>\n<!-- L18&#45;&gt;L19 -->\n<g id=\"edge18\" class=\"edge\"><title>L18&#45;&gt;L19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1716.45,-41C1724.78,-41 1733.61,-41 1742.06,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1742.14,-44.5001 1752.14,-41 1742.14,-37.5001 1742.14,-44.5001\"/>\n</g>\n<!-- L20 -->\n<g id=\"node20\" class=\"node\"><title>L20</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"1896.31\" cy=\"-41\" rx=\"40.0939\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1896.31\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dropout</text>\n</g>\n<!-- L19&#45;&gt;L20 -->\n<g id=\"edge19\" class=\"edge\"><title>L19&#45;&gt;L20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1820.23,-41C1828.18,-41 1836.84,-41 1845.37,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1845.64,-44.5001 1855.64,-41 1845.64,-37.5001 1845.64,-44.5001\"/>\n</g>\n<!-- L21 -->\n<g id=\"node21\" class=\"node\"><title>L21</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"2013.55\" cy=\"-41\" rx=\"40.8928\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"2013.55\" y=\"-37.3\" font-family=\"Times,serif\" font-size=\"14.00\">Softmax</text>\n</g>\n<!-- L20&#45;&gt;L21 -->\n<g id=\"edge20\" class=\"edge\"><title>L20&#45;&gt;L21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1936.64,-41C1944.8,-41 1953.51,-41 1962,-41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1962.21,-44.5001 1972.21,-41 1962.21,-37.5001 1962.21,-44.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### このCNNの認識精度は概ね99%を超す"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## さらに認識精度を高めるには"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "- アンサンブル学習(ensemble learning)\n- 学習系率の減衰(learning rate decay)\n- データ拡張(data aughmentation)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Data Augmentation"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "入力画像を人工的なアルゴリズムによって微小変化させる\n- Crop処理: データを切り出す\n- flip処理: データを回線させる\n- scale処理: データを拡大縮小させる"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 層を深くすることのモチベーション"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "層をいたずらに深くする事の重要性は証明されていないが、昨今の傾向としては層を深くする（認識性能の向上を見込んでいる）方向に向かっている。\n層を深くすることの利点\n- 層を深くしない場合に比べより少ないパラメータで同レベル以上の表現をすることが出来る\n- 特に小さなフィルターを重ねてネットワークを深くすることにより受容野（receptive field）を広くすることが出来る。\n- 層を重ねることでReLU等の活性化関数が畳み込み層の間に挟まれることになり、非線形の力を強める事ができる。\n- 各層が別の特徴を捉えることでCNN全体が一つの特徴以外に囚われなくなる\n    - 各層が学習すべき課題がよりシンプルな問題へと分解される"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## ディープラーニングの少歴史"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "ILSVRC(ImageNet Large Scale Visual Recognition Challenge)でAlexNetが圧倒的成績で優勝したことがブームの始まり"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### ImageNet"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "[ILSVRC(ImageNet Large Scale Visual Recognition Challenge)](http://www.image-net.org/challenges/LSVRC/)は画像認識のコンペティション。  \nその中でもVGG, GoogleLeNet, RasNetが有名。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### VGG"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://www.researchgate.net/figure/A-visualization-of-the-VGG-architecture_fig2_318701491\n![https://www.researchgate.net/profile/Mhaned_Oubounyt/publication/318701491/figure/fig2/AS:520298631446528@1501060268099/A-visualization-of-the-VGG-architecture.png](https://www.researchgate.net/profile/Mhaned_Oubounyt/publication/318701491/figure/fig2/AS:520298631446528@1501060268099/A-visualization-of-the-VGG-architecture.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "VGGは非常にシンプル。3x3フィルタの畳み込み層を連続させ、プーリング層でサイズを半分にする。最後に全結合層を経由して出力。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### GoogLeNet"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/googlenet.html\n![https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/GoogleNet.png](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_5/GoogleNet.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "インセプション構造を1x1のフィルタによる畳み込み層で挟むことでパラメータの削減・処理の高速化をしている"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### ResNet"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "層を深くしすぎると勾配減衰が発生し、最終的な性能が劣るという問題をクリアするために、「スキップ構造」を使っている。\nスキップ構造であ伝搬時も逆伝搬時も入力データをそのまま流すので、勾配の変化がゆるやかになる。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://www.safaribooksonline.com/library/view/practical-computer-vision/9781788297684/12a933e6-e3c6-47d5-9064-512c8a0b4667.xhtml\n![https://www.safaribooksonline.com/library/view/practical-computer-vision/9781788297684/assets/1e122e62-bd2e-4b66-be3f-1a11c5028ec9.png](https://www.safaribooksonline.com/library/view/practical-computer-vision/9781788297684/assets/1e122e62-bd2e-4b66-be3f-1a11c5028ec9.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "ResNetはVGGにスキップ構造を足したもの。  \nhttp://alimurreza.blogspot.com/2017/04/deep-residual-network-resnet.html  \n![https://2.bp.blogspot.com/-J7j0eUkNJ-w/WPU7iXKs6II/AAAAAAAAJt0/FMY6pOVMu34y2TziHnVPbadohKim1XpKACLcB/s640/resnet_vs_plainnet.png](https://2.bp.blogspot.com/-J7j0eUkNJ-w/WPU7iXKs6II/AAAAAAAAJt0/FMY6pOVMu34y2TziHnVPbadohKim1XpKACLcB/s640/resnet_vs_plainnet.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 転移学習\nVGGなど既存のネットワーク構成をそのまま引き継ぐことで学習済みの重みを初期値として新しいデータセットを対象に再学習を行うことを「転移学習」と呼ぶ。手元にあるデータがスクアに場合において転移学習は有効な手法である。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## ディープラーニングの高速化"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "ディープラーニングフレームワークの多くはGPU処理をサポートしているが、最近では複数のGPUや複数の筐体での分散学習にも対応してきている。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 取り組むべき課題"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-93.pdf  \n畳み込み層の処理が最も計算容量が大きい為、学習時・推論時の両方の観点でいかに畳み込み層の計算量を減らすかがカギとなる。\nここで言う畳み込み層の処理とは、元をたどれば大量の積和演算であり、最終的には積和演算をいかに拘束に効率的に処理するかということに行き着く。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### GPUによる高速化"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "NVIDIAが提供するCUDA開発環境を使ってGPUコンピューティングすることができる。特にim2colのように大きな塊を一気に計算できる形式に変換できる関数と相性が良い。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 分散学習による高速化"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "TensorFlowのような分散学習の機能が入ったライブラリを使用すること"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 演算精度のビット削減"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "演算精度のビットを削減しても、そこまで演算結果に影響が無いことが分かっている。一般的に16ビットの半精度浮動小数点数でディープラーニングを行うことができることが分かっている。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### ディープラーニングの実用例"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 物体検出"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://www.quora.com/Where-can-I-find-a-nice-tutorial-for-Regional-based-Convolution-neural-Network\n![https://qph.fs.quoracdn.net/main-qimg-c96241e4e90c2b8509c4b1e87965965a.webp](https://qph.fs.quoracdn.net/main-qimg-c96241e4e90c2b8509c4b1e87965965a.webp)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "物体検出では2.で物体らしき領域を抜き出し、3.で物体の内訳を処理するというフローとなる。  \n2.についてはR-CNNではSelective Searchと呼ばれる手法で実装されているが、最近ではこれもCNNで行う手法が提案されている。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### セグメンテーション"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://www.researchgate.net/figure/Schematic-illustration-of-a-cascaded-CNN-architecture-for-brain-tumor-segmentation-task_fig2_317341396\n![https://www.researchgate.net/profile/Zeynettin_Akkus/publication/317341396/figure/fig2/AS:502178922102784@1496740193411/Schematic-illustration-of-a-cascaded-CNN-architecture-for-brain-tumor-segmentation-task.png](https://www.researchgate.net/profile/Zeynettin_Akkus/publication/317341396/figure/fig2/AS:502178922102784@1496740193411/Schematic-illustration-of-a-cascaded-CNN-architecture-for-brain-tumor-segmentation-task.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "画像のあるエリアを矩形抽出し、推論処理をすると縦x横のピクセル分も計算が必要なため、無駄である。\nそこで、計算する前に一度畳み込みによりエッジ抽出をし、全結合層でもCNNを使い逆畳み込みを実施しデータを抽象化する手法。"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 画像キャブション生成"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://heuristic.exblog.jp/26280459/\n![https://pds.exblog.jp/pds/1/201612/27/04/c0338704_11201262.jpg](https://pds.exblog.jp/pds/1/201612/27/04/c0338704_11201262.jpg)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "CNNと自然言語処理を合わせたもの"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## ディープラーニングの未来"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 画像スタイル変換"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://japanese.engadget.com/2015/08/31/dnn/\n![https://s.aolcdn.com/hss/storage/midas/4268f75101a54385118d379aa4e6d8d3/202560222/artsconsol.jpg](https://s.aolcdn.com/hss/storage/midas/4268f75101a54385118d379aa4e6d8d3/202560222/artsconsol.jpg)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 画像生成"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://qiita.com/sergeant-wizard/items/0a57485bc90a35efcf26\n![https://camo.qiitausercontent.com/535607788a9e18ae42c12b4c3ec8747ed9495073/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f36373231372f34353939396163642d363566372d363439612d313133362d6462316632663164366465612e706e67](https://camo.qiitausercontent.com/535607788a9e18ae42c12b4c3ec8747ed9495073/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f36373231372f34353939396163642d363566372d363439612d313133362d6462316632663164366465612e706e67)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### 自動運転"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://www.semanticscholar.org/paper/End-to-End-Learning-for-Self-Driving-Cars-Bojarski-Testa/0e3cc46583217ec81e87045a4f9ae3478a008227\n![https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/0e3cc46583217ec81e87045a4f9ae3478a008227/3-Figure2-1.png](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/0e3cc46583217ec81e87045a4f9ae3478a008227/3-Figure2-1.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Deep Q-Network (強化学習)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "https://www.toshiba-sol.co.jp/tech/sat/case/1804_1.htm\n![https://www.toshiba-sol.co.jp/tech/sat/case/images/graph_case16_02_gr.png](https://www.toshiba-sol.co.jp/tech/sat/case/images/graph_case16_02_gr.png)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "AlphaGoなど"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}